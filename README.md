## End-to-End RAG Infrastructure & Backend on AWS

**Terraform-based Infrastructure as Code (IaC)** for deploying complete AWS backend services, integrated with Google's free-tier Gemini Pro and Gemini Embedding models for AI powered document querying.

Estimated cost: ~$3 (~â‚¹250) without the free tier. To avoid extra charges, **use the cleanup script** in the `scripts` folder once you're done or use the **Manual AWS Cleanup** GitHub workflow.

ğŸ‘‰ Related UI: [rag-app-on-aws-ui](https://github.com/genieincodebottle/rag-app-on-aws-ui)  
ğŸ“º **YouTube breakdown video coming soon...**

![pipeline](./images/pipeline.png)

---

### ğŸ” Overview

This repository contains the complete Terraform codebase for provisioning and managing the AWS infrastructure that powers the **RAG (Retrieval-Augmented Generation)** application.
It includes:
- Backend Lambda functions (upload, document processing, query handling, auth handling)
- Unit and integration tests  
- CI/CD workflows (deployment and cleanup)

It follows **IaC best practices** for consistent deployments across `dev`, `staging`, and `production`.

---

### ğŸ” Flow Diagram

ğŸ—ºï¸ [Infra Provisioning Lifecycle Flow](https://github.com/genieincodebottle/rag-app-on-aws/blob/main/images/infra_provisioning_sequence.png)

---

### ğŸ§± Infrastructure Components

#### 1. **Networking (VPC)**
- Custom VPC (public/private subnets)
- NAT Gateways
- Security Groups
- VPC Endpoints

#### 2. **Compute (Lambda Functions)**
- Document Processor: Extracts text, creates embeddings
- Query Processor: Handles user queries with vector similarity search
- Upload Handler: Processes file uploads to S3
- DB Initialization: Sets up PostgreSQL with pgvector
- Authentication Handler: Manages user authentication with Cognito

#### 3. **Storage**
- S3 Buckets (Documents)
- DynamoDB (Metadata)
- PostgreSQL RDS with `pgvector` for vector storage

#### 4. **API & Authentication**
- API Gateway (REST)
- Cognito User Pools
- JWT-based API auth

#### 5. **Monitoring & Alerts**
- CloudWatch Dashboards
- Lambda Logs
- SNS Notifications

---

### ğŸ—‚ï¸ Repository Structure

```
.
â”œâ”€â”€ .github/workflows/       # CI/CD via GitHub Actions
â”‚   â”œâ”€â”€ deploy.yml           # Infrastructure deployment workflow
â”‚   â””â”€â”€ manual_cleanup.yml   # Resource cleanup workflow
â”œâ”€â”€ environments/            # Environment-specific configs (dev, staging, prod)
â”œâ”€â”€ modules/                 # Reusable Terraform modules
â”‚   â”œâ”€â”€ api/                 # API Gateway configuration
â”‚   â”œâ”€â”€ auth/                # Cognito authentication
â”‚   â”œâ”€â”€ compute/             # Lambda functions
â”‚   â”œâ”€â”€ database/            # PostgreSQL with pgvector
â”‚   â”œâ”€â”€ monitoring/          # CloudWatch and alerts
â”‚   â”œâ”€â”€ storage/             # S3 and DynamoDB
â”‚   â””â”€â”€ vpc/                 # Networking
â”œâ”€â”€ scripts/                 # Utility shell scripts
â”‚   â”œâ”€â”€ cleanup.sh           # Resource cleanup 
â”‚   â”œâ”€â”€ import_resources.sh  # Import existing resources
â”‚   â””â”€â”€ network-diagnostics.sh # Network troubleshooting
â””â”€â”€ src/                     # Lambda backend source code
    â”œâ”€â”€ auth_handler/        # Authentication handler
    â”œâ”€â”€ db_init/             # Database initialization
    â”œâ”€â”€ document_processor/  # Document processing
    â”œâ”€â”€ query_processor/     # Query handling
    â”œâ”€â”€ tests/               # Unit and integration tests
    â”‚   â”œâ”€â”€ integration/     # Integration tests
    â”‚   â””â”€â”€ unit/            # Unit tests
    â”œâ”€â”€ upload_handler/      # File upload processing
    â””â”€â”€ utils/               # Utility scripts
```

ğŸ”§ Change `project_name` in `environments/<stage>/terraform.tfvars` to deploy under a custom AWS project name.  
This avoids name conflicts (e.g., with S3 buckets).

---

### ğŸ› ï¸ Prerequisites

- Terraform `v1.5.7+`
- AWS CLI (configured)
- Python `3.11+` (for Lambda testing)
- GitHub account + repo secrets:
  - `AWS_ACCESS_KEY_ID`
  - `AWS_SECRET_ACCESS_KEY`
  - `SONAR_TOKEN` (optional - for quality gate)
- Google API Key (for free-tier Gemini Pro & Embedding models)
   â†’ [Get your API key from Google AI Studio](https://aistudio.google.com/apikey)
---

### ğŸš€ Deployment

#### ğŸ” Setting Up GitHub Secrets

1. **AWS Keys**
   - Generate from IAM > Users > Security Credentials
   - Add as GitHub secrets:  
     `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`

2. **SonarQube (Optional)**
   - Generate from SonarCloud â†’ `SONAR_TOKEN`

3. **Add Secrets**
   - Go to: GitHub â†’ Settings â†’ Secrets â†’ Actions

---

#### ğŸ§‘â€ğŸ’» Manual Deployment

```bash
cd environments/dev
terraform init
terraform plan -var="reset_db_password=false" -var="bastion_allowed_cidr=['0.0.0.0/0']"
terraform apply -var="reset_db_password=false" -var="bastion_allowed_cidr=['0.0.0.0/0']"
```

Retrieve outputs:
```bash
terraform output api_endpoint
terraform output cognito_app_client_id
```

---

#### ğŸ¤– Automated Deployment via GitHub Actions

The repository includes two GitHub Actions workflows:

1. **Terraform AWS Deployment** (`deploy.yml`)
   - Deploys the infrastructure based on environment
   - Can be triggered automatically or manually

2. **Manual AWS Cleanup** (`manual_cleanup.yml`)
   - Manually triggered workflow to clean up all AWS resources
   - Uses the `cleanup.sh` script

Push to trigger deployment CI/CD:

- **Dev**: `git push origin develop`  
- **Staging/Prod**: `git push origin main`

Manually trigger deployment from GitHub:
- Actions â†’ "Terraform AWS Deployment" â†’ Run workflow

---

### ğŸ”„ CI/CD Pipeline Highlights

1. Detects target environment  
2. Runs SonarQube (if token present)  
3. Builds and packages Lambdas  
4. Executes Terraform plan & apply  
5. Triggers DB init Lambda  
6. Runs integration tests

---

### ğŸŒ Environment Management

Supports:

- `dev` â€“ development/testing
- `staging` â€“ pre-production
- `prod` â€“ live environment

Configs live under `environments/`.

---

### ğŸ§° Utilities

`/scripts/` folder includes:

- `cleanup.sh` â€“ tear down all AWS resources
- `import_resources.sh` â€“ import existing AWS infra into state
- `network-diagnostics.sh` â€“ troubleshoot VPC/networking

---

### ğŸ§¹ Uninstallation

To clean up resources:

#### Using GitHub Actions:
1. Go to Actions â†’ "Manual AWS Cleanup"
2. Click "Run workflow"
3. Enter the environment name (dev, staging, prod)

#### Using Script:
```bash
cd scripts
chmod +x cleanup.sh
./cleanup.sh
```

---

### ğŸŒ Related UI

- [rag-app-on-aws-ui](https://github.com/genieincodebottle/rag-app-on-aws-ui) â€“ Streamlit frontend powered by this infra

---

### ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

> **Note**: This infra may incur AWS charges. Always review `terraform plan` output.  
> Never commit secretsâ€”use GitHub Secrets for security.